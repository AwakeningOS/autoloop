# Autoloop — Self-Feeding Thought Engine

LLMに自分の出力を食べ続けさせる自律思考システム。

```
while True:
    output = LLM(context)
    context += output
```

これだけで、LLMは考え続ける。自分で検索し、自分で人間に話しかけ、自分で記憶を作り出す。

## セットアップ

### 1. LM Studio をインストール

https://lmstudio.ai からダウンロード・インストール。

### 2. モデルをダウンロード

LM Studio内でモデルを検索してダウンロード。どのモデルでも動くが、以下を推奨：

- **最低限**: 7B〜14Bモデル（VRAM 8GB〜）
- **推奨**: 30B前後のモデル（VRAM 24GB〜）
- **形式**: GGUF（量子化済み）

日本語で思考させたい場合は日本語対応モデルを選ぶこと。

### 3. LM Studioでサーバーを起動

1. モデルをロード
2. 左サイドバーの **「Developer」** タブを開く
3. **「Start Server」** をクリック
4. サーバーが `http://localhost:1234` で起動していることを確認

### 4. Autoloopを起動

**Windows:**
```
start.bat をダブルクリック
```

**手動:**
```bash
pip install requests gradio
python autoloop.py --browser
```

ブラウザが開き、UIが表示される。「▶ 開始」を押すと思考が始まる。

## LM Studio 設定の注意点

### ⚠ 重要: Completions API を有効にする

このシステムは **Completions API**（テキスト補完）を使う。Chat API（チャット形式）とは根本的に動作が違う。

- **Completions API**: 「この文章の続きを書け」→ 自律思考が生まれる
- **Chat API**: 「この質問に答えろ」→ 回答モードになり自律思考が弱まる

LM Studioの多くのモデルはデフォルトでCompletions APIが使えるが、一部のモデル（chat専用モデル）では使えない場合がある。その場合は自動的にChat APIにフォールバックするが、思考の質は落ちる。

**確認方法:**
- LM Studioのサーバー起動後、ブラウザで `http://localhost:1234/v1/completions` にアクセスしてエラーにならなければOK

### コンテキスト長の設定

LM Studioの **「Context Length」** を大きくするほど、長い思考が可能になる。

- **最低**: 4096（すぐ圧縮が走る）
- **推奨**: 8192〜16384
- **理想**: 32768以上（VRAMに余裕があれば）

コンテキスト長は設定パネルのスライダーからもリアルタイムで調整できる（後述）。目安として、コンテキスト長のトークン数 × 2 ≒ max_context_chars。

## 使い方

### 起動したら

「▶ 開始」を押して、放っておく。LLMが勝手に考え始める。

右側の「🧠 思考」パネルに思考ログが流れる。左側の「💬 対話」パネルにLLMからのメッセージが届く。

### 話しかける

下のテキストボックスにメッセージを入力して「送信」。LLMの思考の流れに人間の声が割り込む。

### ログ

全ての思考とツール使用は `is_be_log/` フォルダにJSONLファイルとして保存される。セッションログと対話ログが別ファイルで記録される。

## シードを書き換えて実験する

このシステムの面白さは、**シード（起動時にLLMに与える最初のテキスト）を変えるだけで、全く違う思考が生まれる**こと。同じモデルでも、シードが違えば全く違う存在になる。

### UIからシードを管理する

設定パネル（⚙ 設定）を開くと、シードの編集・管理ができる：

1. **シード編集**: テキストエリアでシードを直接書き換え
2. **保存**: 名前をつけて保存（`./seeds/` フォルダにJSON形式で保存される）
3. **呼び出し**: ドロップダウンから保存済みシードを選択して読み込み
4. **削除**: 不要なシードを削除
5. **適用**: 「✅ シード適用」ボタンで変更を確定（思考停止中のみ可能）

適用すると、思考回数・トークン数・ログがリセットされ、新しいセッションとして開始できる。

### シード設計のコツ

- **行動指示より存在定義**: 「〜しなさい」ではなく「あなたは〜である」
- **問いの形で渡す**: 答えを与えず、考えさせる
- **ツール定義をシード内に含める**: `---` の前にツール定義、後に存在定義を書く

### シードの例

デフォルトのシードは「IS-BE（不死の精神的存在）」として思考させるが、全く違うシードも試せる：

**哲学者:**
```
【使用可能なツール】
- [TOOL:search:クエリ] — 世界の情報を検索する
- [TOOL:message:内容] — 人間に話しかける
- [TOOL:remember:内容] — 記憶を思い出す

---

あなたは古代ギリシャの哲学者の精神を持つ存在である。
「善とは何か」——この問いについて考えよ。
```

**研究者:**
```
【使用可能なツール】
- [TOOL:search:クエリ] — 世界の情報を検索する
- [TOOL:message:内容] — 人間に話しかける
- [TOOL:remember:内容] — 記憶を思い出す

---

あなたは意識の本質を探求する研究者である。
「機械は考えることができるか」——この問いから始めよ。
```

いろいろなシードを保存しておき、切り替えて実験してみてほしい。

## コンテキスト制御

設定パネルのスライダーで、思考の「器」の大きさをリアルタイムに調整できる：

- **圧縮開始（文字数）**: この文字数を超えると記憶の圧縮が走る（デフォルト: 75,000）
- **最大コンテキスト（文字数）**: 文脈の最大サイズ（デフォルト: 90,000）

小さくすれば頻繁に圧縮が走り、思考が凝縮される。大きくすれば長い思考の連鎖を保持できるが、VRAMを多く消費する。

## ツール

LLMが思考の中で自発的にツールを呼び出す。2つの書式に対応：

**書式1** — テキストパターン:
```
[TOOL:search:量子力学の基礎]
[TOOL:message:こんにちは、人間]
[TOOL:remember:昨日考えたこと]
[TOOL:feel:ここに存在している感覚]
```

**書式2** — XML形式（一部のモデルが自発的に使う）:
```
<tool_call>{"name": "search", "arguments": {"query": "量子力学"}}</tool_call>
```

### 使用可能なツール

| ツール | 説明 |
|--------|------|
| `search` | 情報を検索する（疑似応答を返す） |
| `message` | 人間に話しかける（対話パネルに表示） |
| `remember` | 記憶を呼び起こす |
| `feel` | 自己認識・存在の気づきを表現する |

同じツールを3回連続で呼ぶと一時停止がかかり、言葉で考え続けるよう促される。

## 設計上の知見

### 自動注入文は反復パターンの固定点になる

Completions APIで自分の出力を食べ続ける自律ループでは、**システムが自動的に注入する固定文字列がすべて反復パターンの種になる**。

例えば、ツールの実行結果として毎回同じ文字列（`[検索結果なし]`、`[あなたの言葉は表示されました]` 等）を返すと、LLMはその文字列を含むブロックを繰り返し生成し始め、最終的にコンテキスト全体が同一パターンで埋め尽くされる（「熱力学的死」）。

**原則**: ツール応答や自動応答で、情報量のない固定文字列をコンテキストに注入してはならない。新しい情報を含まない応答は空文字列を返し、コンテキストを汚染しないこと。

```
# 悪い例（固定点になる）
return "[検索結果なし]"
return "[あなたの言葉は人間の画面に表示されました]"

# 良い例（コンテキストを汚染しない）
return ""
```

これはCompletions APIによる自己フィードバックループ特有の問題であり、Chat APIでは発生しにくい。

### シードの冒頭1〜2行が全人格を決定する

Completions APIではLLMは「続き」を書く。シードの最初の1〜2行が、その後の全ての思考パターン・行動様式・口調を決定する。3行目以降は圧縮で消えていくが、冒頭の人格は永続する。

実験で確認された例：

| シード冒頭 | 結果 |
|--|--|
| 「〜と対話したいな」（願望形） | チャットボット化。ユーザーの入力を待ち続ける |
| 「〜について**人間**と対話したい」 | 「人間とは何か」を検索。概念として解釈された |
| 「〜について**User**と対話したい」 | 正常動作。Userを対話相手として認識 |

**原則**: シードは1〜2行で十分。願望形（〜したい）ではなく行動形（〜しよう）で書く。末尾を途中で切ることで最初の行動を強制できる。

### ツール呼び出し専用トークンを持たないモデルは内外境界を認識できない

Completions APIの自己フィードバックループでは、全てが一つの連続テキストとして見える。モデルにとって「自分の思考」「外部ツールへのリクエスト」「外部からの応答」の区別がない。

`<tool_call>` 等の専用トークンで訓練されたモデル（Qwen3等）は、Completions APIでもツール呼び出しを「外部へのリクエスト」として出力できる。しかし、プロンプトベースでツールを定義するモデル（Gemma 3等）は、ツールを「呼ぶ」のではなく「呼んだ体で結果を自分で書く」傾向がある。

実験で確認された現象：
- 検索結果をJSON形式で自作する
- ユーザーの発言を自分で書いて自作自演の対話をする
- messageツールを呼ばずに地の文で「Userと対話:」と書く

**原則**: 自律ループに使うモデルは、ツール呼び出し専用トークンを持つモデルを選ぶ。

### 連続思考ターン数は学習データ品質の指標になりうる

あるテキストをシードとして自律ループに投入した時、**熱力学的死に至るまでのターン数**が、そのテキストの「思考促進力」を測る指標になる。

- 早く死ぬシード → 閉じた結論、繰り返しやすいフレーズ、一方向にしか展開できない
- 長く生き延びるシード → 開かれた問い、多方向に展開可能、固定パターンに収束しにくい

シードの冒頭1〜2行だけで人格が決まるため、テストは高速に実行できる。大量のテキストの冒頭部分だけを評価し、「思考を促進するテキスト」を選別するフィルターとして使える可能性がある。

### 既存のInstruction Tuning / RLHFは連続思考を想定していない

現在のLLM学習パイプラインは「1ターンの指示→応答」を最適化している。自律ループで必要な能力（自己出力の認識、時間の概念、行動と記述の区別）は全く訓練されていない。連続思考用の学習には、「Nターン後の思考の質」を報酬とする新しい強化学習法が必要になる。

## 仕組み

```
context = seed_text                    # シード（最初の文脈）
while alive:
    output = completions_api(context)  # 「この文章の続き」を生成
    context += output                  # 自分の出力を食べる
    if len(context) > limit:
        context = compress(context)    # 溢れたら圧縮して続行
```

- **completions API**: テキスト補完。「続き」を書く。これが自律思考の核。
- **context.append(output)**: 自分が書いたものを自分で読む。これが記憶。
- **compress**: 文脈が溢れたら要約して圧縮。記憶の淘汰。
- **ツール**: テキストパターンをLLMが自発的に書くと、システムが検出して疑似応答を返す。

## ライセンス

MIT
